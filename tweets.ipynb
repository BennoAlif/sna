{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import tweepy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms.community import greedy_modularity_communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAEkYWAEAAAAAiCZ95QEqxNKuluivi0dNKwu%2BUIA%3DpXPhzD5xrJFlCx6roDUnzjJ6jtuh8wr2AyPhfZls4g4Yo4kH8y\"\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = '#racunshopee OR \"racun shopee\" OR \"shopee haul\" OR #shopeehaul lang:id'\n",
    "query = '((\"rekomendasi\" OR \"referensi\" OR \"inspirasi\") (\"outfit\" OR \"baju\" OR \"OOTD\")) OR (\"outfit of the day\" OR \"OOTD\") lang:id'\n",
    "# query = 'eiger lang:id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data = []\n",
    "tweets_user = []\n",
    "\n",
    "for response in tweepy.Paginator(client.search_recent_tweets,\n",
    "                                query=query,\n",
    "                                # start_time=start_time,\n",
    "                                # end_time=end_time,\n",
    "                                tweet_fields = [\"created_at\", \"text\", \"author_id\", \"entities\", \"in_reply_to_user_id\"],\n",
    "                                user_fields = [\"name\", \"username\", \"location\", \"verified\", \"description\"],\n",
    "                                max_results = 100,\n",
    "                                expansions='author_id', limit=100):\n",
    "  \n",
    "    tweets_data += response.data\n",
    "    tweets_user += response.includes[\"users\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data_df = pd.DataFrame(tweets_data)\n",
    "tweets_user_df = pd.DataFrame(tweets_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = tweets_user_df.rename(columns={\"id\": \"author_id\"})\n",
    "tweets_df = tweets_df.drop_duplicates()\n",
    "df = tweets_data_df.merge(tweets_df, left_on='author_id', right_on='author_id')\n",
    "df.to_csv(\"tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions = []\n",
    "for i in tweets_data:\n",
    "  if(i[\"entities\"] is not None):\n",
    "    if \"mentions\" in i[\"entities\"]:\n",
    "      for j in i[\"entities\"][\"mentions\"]:\n",
    "        # print(j[\"id\"], j[\"username\"])\n",
    "        mention = {\n",
    "          \"id\": i[\"id\"],\n",
    "          \"mention_id\": j[\"id\"],\n",
    "          \"mention_username\": j[\"username\"]\n",
    "        }\n",
    "        mentions.append(mention)\n",
    "      # print(i[\"id\"])\n",
    "\n",
    "mentions_df = pd.DataFrame(mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_mention_df = mentions_df.merge(df, left_on='id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mentions_df = tweets_mention_df.rename(columns={\"username\": \"source\", \"mention_username\": \"target\"})\n",
    "user_mentions_df = user_mentions_df[[\"source\", \"target\"]]\n",
    "user_mentions_df = user_mentions_df.drop_duplicates(keep= 'first', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_reply_to_user_df = df[df['in_reply_to_user_id'].notna()]\n",
    "# in_reply_to_user_df = in_reply_to_user_df.rename(columns={\"username\": \"source\"})\n",
    "in_reply_to_user_df = in_reply_to_user_df.merge(df, left_on='in_reply_to_user_id', right_on='author_id')\n",
    "in_reply_to_user_df = in_reply_to_user_df.rename(columns={\"username_x\": \"source\",\"username_y\": \"target\"})\n",
    "in_reply_to_user_df = in_reply_to_user_df[[\"source\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([in_reply_to_user_df, user_mentions_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_names = [n for n in df[\"username\"]] # Get a list of only the node names\n",
    "records  = final_df.to_records(index=False)\n",
    "edges = list(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from(node_names)\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density = nx.density(G)\n",
    "print(\"Network density:\", density)\n",
    "plt.figure(figsize=(10,10))\n",
    "nx.draw_networkx(G, with_labels=True,\n",
    "        node_color='skyblue',\n",
    "        # node_size=1200,\n",
    "        arrowstyle='->',\n",
    "        arrowsize=20,\n",
    "        edge_color='red',\n",
    "        font_size=9,\n",
    "        pos=nx.kamada_kawai_layout(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your Graph has more than one component, this will return False:\n",
    "print(nx.is_connected(G))\n",
    "\n",
    "# Next, use nx.connected_components to get the list of components,\n",
    "# then use the max() command to find the largest one:\n",
    "components = nx.connected_components(G)\n",
    "largest_component = max(components, key=len)\n",
    "\n",
    "# Create a \"subgraph\" of just the largest component\n",
    "# Then calculate the diameter of the subgraph, just like you did with density.\n",
    "#\n",
    "\n",
    "subgraph = G.subgraph(largest_component)\n",
    "diameter = nx.diameter(subgraph)\n",
    "print(\"Network diameter of largest component:\", diameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triadic_closure = nx.transitivity(G)\n",
    "print(\"Triadic closure:\", triadic_closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_dict = dict(G.degree(G.nodes()))\n",
    "nx.set_node_attributes(G, degree_dict, 'degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "sorted_degree = sorted(degree_dict.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 20 nodes by degree:\")\n",
    "for d in sorted_degree[:20]:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness_dict = nx.betweenness_centrality(G) # Run betweenness centrality\n",
    "# eigenvector_dict = nx.eigenvector_centrality(G) # Run eigenvector centrality\n",
    "\n",
    "# Assign each to an attribute in your network\n",
    "nx.set_node_attributes(G, betweenness_dict, 'betweenness')\n",
    "# nx.set_node_attributes(G, eigenvector_dict, 'eigenvector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_betweenness = sorted(betweenness_dict.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "print(\"Top 20 nodes by betweenness centrality:\")\n",
    "for b in sorted_betweenness[:20]:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import community #This part of networkx, for community detection, needs to be imported separately.\n",
    "\n",
    "communities = community.greedy_modularity_communities(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modularity_dict = {} # Create a blank dictionary\n",
    "for i,c in enumerate(communities): # Loop through the list of communities, keeping track of the number for the community\n",
    "    for name in c: # Loop through each person in a community\n",
    "        modularity_dict[name] = i # Create an entry in the dictionary for the person, where the value is which group they belong to.\n",
    "\n",
    "# Now you can add modularity information like we did the other metrics\n",
    "nx.set_node_attributes(G, modularity_dict, 'modularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get a list of just the nodes in that class\n",
    "class0 = [n for n in G.nodes() if G.nodes[n]['modularity'] == 0]\n",
    "\n",
    "# Then create a dictionary of the eigenvector centralities of those nodes\n",
    "class0_degree = {n:G.nodes[n]['degree'] for n in class0}\n",
    "\n",
    "# Then sort that dictionary and print the first 5 results\n",
    "class0_sorted_by_degree = sorted(class0_degree.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "print(\"Modularity Class 0 Sorted by degree Centrality:\")\n",
    "for node in class0_sorted_by_degree[:5]:\n",
    "    print(\"Name:\", node[0], \"| degree Centrality:\", node[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,c in enumerate(communities): # Loop through the list of communities\n",
    "#     if len(c) > 2: # Filter out modularity classes with 2 or fewer nodes\n",
    "#         print('Class '+str(i)+':', list(c)) # Print out the classes and their members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "nx.draw_networkx(G, with_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this returns a list of set of nodes belonging to the \n",
    "# different (weakly) connected components\n",
    "components = list(nx.connected_components(G))\n",
    "\n",
    "# sort the component according to their size\n",
    "components = list(sorted(components, key=lambda x:len(x), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list with the size of each component\n",
    "comp_sizes = []\n",
    "for comp in components:\n",
    "    comp_sizes.append(len(comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the histogram of component sizes\n",
    "hist = plt.hist(comp_sizes, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a new graph which is the subgraph of G corresponding to \n",
    "# the largest connected component\n",
    "# let's find the largest component\n",
    "largest_comp = components[0]\n",
    "LCC = G.subgraph(largest_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(LCC, with_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCC.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.random_geometric_graph(200, 0.125)\n",
    "# position is stored as node attribute data for random_geometric_graph\n",
    "pos = nx.get_node_attributes(G, 'pos')\n",
    "\n",
    "# find node near center (0.5,0.5)\n",
    "dmin = 1\n",
    "ncenter = 0\n",
    "for n in pos:\n",
    "    x, y = pos[n]\n",
    "    d = (x - 0.5)**2 + (y - 0.5)**2\n",
    "    if d < dmin:\n",
    "        ncenter = n\n",
    "        dmin = d\n",
    "\n",
    "# color by path length from node near center\n",
    "p = dict(nx.single_source_shortest_path_length(G, ncenter))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "nx.draw_networkx_edges(G, pos, nodelist=[ncenter], alpha=0.4)\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=list(p.keys()),\n",
    "                       node_size=80,\n",
    "                       node_color=list(p.values()),\n",
    "                       cmap=plt.cm.Reds_r)\n",
    "\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.ylim(-0.05, 1.05)\n",
    "# plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "# This example needs Graphviz and either PyGraphviz or pydot.\n",
    "# from networkx.drawing.nx_pydot import graphviz_layout as layout\n",
    "from networkx.drawing.nx_agraph import graphviz_layout as layout\n",
    "\n",
    "# If you don't have pygraphviz or pydot, you can do this\n",
    "# layout = nx.spring_layout\n",
    "\n",
    "\n",
    "n = 150  # 150 nodes\n",
    "# p value at which giant component (of size log(n) nodes) is expected\n",
    "p_giant = 1.0 / (n - 1)\n",
    "# p value at which graph is expected to become completely connected\n",
    "p_conn = math.log(n) / float(n)\n",
    "\n",
    "# the following range of p values should be close to the threshold\n",
    "pvals = [0.003, 0.006, 0.008, 0.015]\n",
    "\n",
    "region = 220  # for pylab 2x2 subplot layout\n",
    "plt.subplots_adjust(left=0, right=1, bottom=0, top=0.95, wspace=0.01, hspace=0.01)\n",
    "for p in pvals:\n",
    "    G = nx.binomial_graph(n, p)\n",
    "    pos = layout(G)\n",
    "    region += 1\n",
    "    plt.subplot(region)\n",
    "    plt.title(f\"p = {p:.3f}\")\n",
    "    nx.draw(G, pos, with_labels=False, node_size=10)\n",
    "    # identify largest connected component\n",
    "    Gcc = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "    G0 = G.subgraph(Gcc[0])\n",
    "    nx.draw_networkx_edges(G0, pos, edge_color=\"r\", width=6.0)\n",
    "    # show other connected components\n",
    "    for Gi in Gcc[1:]:\n",
    "        if len(Gi) > 1:\n",
    "            nx.draw_networkx_edges(\n",
    "                G.subgraph(Gi), pos, edge_color=\"r\", alpha=0.3, width=5.0,\n",
    "            )\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "671a6aa7e5f53b45fe807cb744f50ebce4c530f21920d4a62ee77cb740d991f9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
